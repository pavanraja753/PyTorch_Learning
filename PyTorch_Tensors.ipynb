{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Tensors",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOA5WkV/4c9bcI+b9okfXa1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavanraja753/PyTorch_Learning/blob/main/PyTorch_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-6PhfzvLhB0j"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "cifat = CIFAR10('./',train=True,download=True)"
      ],
      "metadata": {
        "id": "12K7QOdqhEMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In-place operations are suffixed with an underscore.\n",
        "- and a 0d tensor can be converted back to a Python scalar with `item()`"
      ],
      "metadata": {
        "id": "BX1HgWrineBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2,5)\n",
        "x.size()\n",
        "x.fill_(1.125)\n",
        "x.mean()\n",
        "x.std()\n",
        "x.sum()\n",
        "x.sum().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq5vAAMkhPEF",
        "outputId": "b79ee1ad-5b60-44c6-d917-6c9e5a6e6be2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.25"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`size()` returns the size / shape of the tensor and has as many components as the number of dimensions of the tensor. E.g. a tensor of size `torch.Size([2, 5])` is a matrix with two rows and five columns.\n",
        "\n",
        "We should use `item()` when printing a single value (to a text file for instance), otherwise `tensor(...)` is printed.\n",
        "\n",
        "The default tensor type `torch.Tensor` is an alias for `torch.FloatTensor`, but there are others with greater/lesser precision and on CPU/GPU. It can be set to a different type with `torch.set_default_tensor_type`. We will come back to this."
      ],
      "metadata": {
        "id": "LVMk5Ob-oZkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For instance an element of R3 is a three-dimension vector, but a one-dimension tensor."
      ],
      "metadata": {
        "id": "-_PtI3v0ow1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.sum().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azr4yNq9nYfn",
        "outputId": "8e1443af-1c54-429b-f48f-68e9a318c340"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.25"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch provides operators for component-wise and vector/matrix operations"
      ],
      "metadata": {
        "id": "dggGAHLpo5xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([10.,20.,30.])\n",
        "y = torch.tensor([11.,21.,31.])"
      ],
      "metadata": {
        "id": "HTVk6rKcnaiC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x + y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klcL0V8ipB46",
        "outputId": "01cc618b-8057-4737-8a22-0ab98e6abc28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([21., 41., 61.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x * y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmPdHstTpDKt",
        "outputId": "8e763e59-b5c8-4fed-c690-dce1da25365c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([110., 420., 930.])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHr9MmgYpEeD",
        "outputId": "5bcd8916-f367-4fb6-cd8d-2ea9fb710759"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100., 400., 900.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.tensor([[0.,0.,3.],\n",
        "                  [0,2,0],\n",
        "                  [1,0,0]])\n",
        "\n",
        "m.mv(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1piMMwopGWq",
        "outputId": "6c78f009-4278-4d3f-b913-0625b6541f1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([90., 40., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m @ x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6LAjBnxpWk5",
        "outputId": "9e5c4194-760c-4272-899b-3bf44d2585cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([90., 40., 10.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `@` operator corresponds to matrix/vector or matrix/matrix multiplication, while `*` is component-wise product and can be applied to tensors of arbitrary size, in particular of dimension greater than 2"
      ],
      "metadata": {
        "id": "d3cDGHxPptIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And as in `NumPy`, the `:` symbol defines a range of values for an index and allows to slice tensors."
      ],
      "metadata": {
        "id": "N_5Xs-hdp7m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.empty(2,4).random_(10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WLjmxnEpYjQ",
        "outputId": "42e7774d-95f4-41fa-9cb7-cab56b6eba75"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 5., 6., 9.],\n",
              "        [1., 6., 5., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5wBAta-qFP0",
        "outputId": "6273cf98-abd2-423a-bcee-482b98dbfd1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 5., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJmpVWlMqLsk",
        "outputId": "bdacea29-ccdb-44a8-cb7d-c67048c9cb5f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 5., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgjYWanfqN8l",
        "outputId": "3b2638fc-0bf9-4bb7-a4ea-ea9d5a18cb80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,1:3] = -1"
      ],
      "metadata": {
        "id": "HcXP7JclqPSD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn148zPtqS5y",
        "outputId": "1e6a00b8-1cca-4aac-94e6-07e7b310464b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3., -1., -1.,  9.],\n",
              "        [ 1., -1., -1.,  1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`PyTorch` provides interfacing to standard linear operations, such as linear system solving or eigen decomposition"
      ],
      "metadata": {
        "id": "n-sVlXLjqb1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.empty(3).normal_()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnT5IAANqTPn",
        "outputId": "4ce0d865-51e5-4d82-b7fd-263dab9dc1b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3125, -0.5410, -1.0462])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.empty(3,3).normal_()"
      ],
      "metadata": {
        "id": "rHYsM-Tfqhhc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q, _ = torch.lstsq(y,m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzcQbbVjqobD",
        "outputId": "e78fe71b-2777-484c-eccf-959fa7e17992"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
            "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
            "To get the qr decomposition consider using torch.linalg.qr.\n",
            "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
            "The unpacking of the solution, as in\n",
            "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
            "should be replaced with\n",
            "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:3668.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mm(m,q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdJ8DYjAq1I0",
        "outputId": "9a7057a4-77e5-4164-b385-62e5b79b1fa9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3125],\n",
              "        [-0.5410],\n",
              "        [-1.0462]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m @ q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ1sAJs5q8Na",
        "outputId": "7e43e455-fd32-4fd4-e5cb-1de1d563d34f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3125],\n",
              "        [-0.5410],\n",
              "        [-1.0462]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.5. High dimension tensors"
      ],
      "metadata": {
        "id": "WL6ERjRrr4IZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor can be of several types\n",
        "\n",
        "- `torch.float16, torch.float32, torch.float64`,\n",
        "- `torch.uint8`,\n",
        "- `torch.int8, torch.int16, torch.int32, torch.int64`\n",
        "\n",
        "\n",
        "\n",
        "and can be located eighter in the CPU's or in a GPU's memory\n",
        "\n",
        "\n",
        "\n",
        "Operations with tensors stored in a certain device’s memory are done by that device. We will come back to that later.\n",
        "\n",
        "*All the coefficients in a given tensor are of the same type, which can be either an integer or floating point value of a certain precision.*\n",
        "\n"
      ],
      "metadata": {
        "id": "uZDOd6sKr8lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(1,3)\n",
        "x.dtype, x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pfuBvN7q-qP",
        "outputId": "bb022978-36fc-4c9f-a200-6a29a8125441"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.long()\n",
        "x.dtype, x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t7FAgZ_svad",
        "outputId": "773bd69e-6779-4a6f-dbd4-c240ecbeecbf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.int64, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to('cuda')"
      ],
      "metadata": {
        "id": "GyjjEnVjszg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The deafault type of tensor values is `torch.float32`, and the deafualt computing device is the CPU.\n",
        "\n",
        "- The data type od the tensor can be accesses with `dtype` and the device on which the tensor lies with `device`\n",
        "\n",
        "- When casting a tensor to a new type (for instance here with x = x.long()), a copy is actually made. If the type is already adequate, a reference to the same tensor is returned.\n",
        "\n",
        "- It is a best practice to define the device that is going to be used once for all at the beginning of a program, and use the method to(device) to move the data to the target device"
      ],
      "metadata": {
        "id": "H2hiPVbgtJxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Higher dimensions\n",
        "\n",
        "- A 2d tensor can be seen as a grayscale image: the first index is the row, and the second index the column.\n",
        "\n",
        "- A 3d tensor can be viewed as a RGB image. The standard in PyTorch is to have the channel index first. For instance, a CIFAR10 image is of size `3×32×32`.\n",
        "\n",
        "- A 4d tensor can be seen as a sequence of multi-channel images. For instance, given a minibatch `batch` of 10 CIFAR10 images is of size `10×3×32×32`,\n",
        "\n",
        "\n",
        "- the 5th image can be accessed as `batch[4]`\n",
        "- the blue channel (3rd) of the 7th image can be accessed with `batch[6, 2]` or `batch[6, 2, :, :]`"
      ],
      "metadata": {
        "id": "s7qYnY6wt3It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1,3,0],[2,4,6]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoGT4I29s4Oa",
        "outputId": "4c38041d-ec97-45df-bee7-49373b2a4903"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 0],\n",
              "        [2, 4, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.t()\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZfXtSN1vCbE",
        "outputId": "dea5fbad-ec2f-4c5a-e7e1-de0b77fc36ac"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 0],\n",
              "        [2, 4, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKg-vOcpvE6W",
        "outputId": "15ab60a2-92b3-4196-9b23-786ca7f2b38c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 0, 2, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJiQCwprvMTG",
        "outputId": "4604ec83-b853-4429-c152-1123d32ee819"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3, 0],\n",
              "        [2, 4, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(3,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhadtecOvVaK",
        "outputId": "a3627b71-f05a-4441-94e5-48b103b88034"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 3],\n",
              "        [0, 2],\n",
              "        [4, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i-S3zG-vZJu",
        "outputId": "d7e2e0f4-49e1-4d15-e350-5d7f7857c4e2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3, 0],\n",
              "        [4, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(1,2,3).expand(3,2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljIAG_LwvjVa",
        "outputId": "bffbfa0e-34e7-4045-990d-849096a4dee6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 3, 0],\n",
              "         [2, 4, 6]],\n",
              "\n",
              "        [[1, 3, 0],\n",
              "         [2, 4, 6]],\n",
              "\n",
              "        [[1, 3, 0],\n",
              "         [2, 4, 6]]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - `t()` can be applied to a 2d tensor and simply transpose the indices, as a classical matrix transpose\n",
        "\n",
        " - `view()` unfolds the tensor in a differnet shape. Using `-1` for one of the dimension copmuted the proper value to match the number of coefficients with the original tensor.\n",
        "\n",
        " - Here, `x.view(1,2,3).expand(3, 2, 3)` can also be acheived with `x.unsqueeze(0).expand(3,2,3)`"
      ],
      "metadata": {
        "id": "5ZF45Awav4dM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Transposing two dimensions of a tensor can also be done by specifying the two dimensions as input: `transpose(dim0, dim1)`. This is of course applicable to tensors of greater than two dimensions"
      ],
      "metadata": {
        "id": "OJh4b3yfFUnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([\n",
        "                  [[1,2,1],\n",
        "                   [2,1,2]],\n",
        "                  [[3,0,3],\n",
        "                  [0,3,0]]\n",
        "])"
      ],
      "metadata": {
        "id": "47dEvScRvskQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EChf295Kv24T",
        "outputId": "eab3702e-dfc0-475b-d870-c319c5d1e4cc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0:1,:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0MGiW7RFzXz",
        "outputId": "3e71fd9c-b874-4d31-d098-a108b8653242"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 1],\n",
              "         [2, 1, 2]]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.transpose(0,1)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EudtrWhFF2Ls",
        "outputId": "ff5009cd-05b7-4885-f9e5-943385c550a6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.transpose(1,2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4oNvozrF_ik",
        "outputId": "39bd5647-64bf-4849-c207-bb16529b4262"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For efficiency reasons, different tensors can share the same data and 􏰂 modifying one will modify the others. By default do not make the\n",
        "assumption that two tensors refer to different data in memory.**"
      ],
      "metadata": {
        "id": "rkkXg-_-GPqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a= torch.full((2,3),1)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRUvGM9eGDv1",
        "outputId": "99a99129-628c-4f49-9772-7d966973a16f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.view(-1)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAbjuMj7GaLp",
        "outputId": "008e3d27-c27d-407b-a9b8-a8e542aa4550"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[1,1] = 2"
      ],
      "metadata": {
        "id": "tKQwFAAYGd63"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78X9oN0oGh1R",
        "outputId": "8a2276c8-1a1f-459d-a643-143c8261a115"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b[0]=9\n",
        "print(b)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVeK0UIzGieq",
        "outputId": "6dfe0d71-1e24-4fef-855a-76477e5fbb07"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 1, 1, 1, 2, 1])\n",
            "tensor([[9, 1, 1],\n",
            "        [1, 2, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that many operations returns a new tensor which shares the same underlying storage as the original tensor, so changing the values of one will change the other as well: `view`, `transpose`, `squeeze`, `unsqueeze`, `expand`, `permute,` etc."
      ],
      "metadata": {
        "id": "YKBu5t3zGwDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PyTorch offers simple interfaces to standard image databases"
      ],
      "metadata": {
        "id": "5Jmtin3KG5M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "\n",
        "cifar = torchvision.datasets.CIFAR10(\"./\",train=True,download=True)\n",
        "cifar.data.shape\n",
        "x = torch.from_numpy(cifar.data).permute(0,3,1,2).float()/255.0\n",
        "print(x.dtype, x.size(), x.min().item(), x.max().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqh_B7riGmvw",
        "outputId": "1abf960d-e5a4-409b-f7d3-2d18dceea16c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "torch.float32 torch.Size([50000, 3, 32, 32]) 0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note that there are different storage conventions between some libraries used by `PyTorch` (`pillow and NumPy`) and PyTorch itself:\n",
        "\n",
        "   \n",
        "\n",
        "1.   loading the images yields a tensor of shape `50000×32×32×3`, but `PyTorch` works with the channel dimension as the second one: `50000×3×32×32.`\n",
        "\n",
        "2.   This change is made with `permute(0, 3, 1, 2)` which means that we want dimension 3 of the original tensor to lie at the second position of the new tensor."
      ],
      "metadata": {
        "id": "xPocMyh4H_LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Narrows to the first images, converts to float\n",
        "x = x[:48]\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjEjRhrIHPzx",
        "outputId": "79b78f96-35cc-4ec8-c33e-2328e986db10"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([48, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saves these images as a single image\n",
        "torchvision.utils.save_image(x,'cifar.png',nrow=12)"
      ],
      "metadata": {
        "id": "L5sjPfWoIh5M"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switches the row and column indexes\n",
        "x = x.transpose_(3,2)\n",
        "torchvision.utils.save_image(x,'cifar.png',nrow=12)"
      ],
      "metadata": {
        "id": "MYDmeW9rI1FU"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data follows the standard `PyTorch` “channel first” convention, transposing\n",
        "dimensions 2 and 3 (that is the 3rd and the fourth) exchanges the height and width of the images.\n",
        "Remember that functions ending with an underscore operate in-place."
      ],
      "metadata": {
        "id": "aViG2zmRJUDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kills the green and blue channels\n",
        "x[:,1:3].fill_(0)\n",
        "torchvision.utils.save_image(x,'cifar.png',nrow=12)"
      ],
      "metadata": {
        "id": "ssaUg211JCiq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting and Einstein summations"
      ],
      "metadata": {
        "id": "k76rF1qYKsB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting automagically expands dimensions by replicating coefficients, when it is necessary to perform operations that are “intuitively reasonable”."
      ],
      "metadata": {
        "id": "f9uBhRSfKx9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(100,4).normal_(2)\n",
        "x.mean(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ANBns1GJr2p",
        "outputId": "b2f85a18-b0a4-4b9d-be24-e48f2ddd354e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x- x.mean(0)"
      ],
      "metadata": {
        "id": "xX-dLr4OK7s3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axZILREULEgi",
        "outputId": "d4ec7b48-a15d-4fc3-c3d2-51d47a7ab4bb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7.7486e-08,  1.5497e-07, -1.1921e-09, -5.2452e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Broadcasting is a mechanism taken from NumPy which expands the proper dimensions of size 1 to perform operations on tensors/arrays of different dimensions.\n",
        "\n",
        "- In the example above, considering that a `N × D` tensor is a list of `N` vectors of dimension `D`, we want to compute the mean vector. So, here, starting from a tensor of dimension `(100, 4)`, the mean along dimension `0` yields a tensor with 4 values of size `(4,)`, one for each column."
      ],
      "metadata": {
        "id": "-FuiFZ_JLKbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is quite natural to substract a vector to a series of vectors. For instance here, it seems reasonable to subtract the mean vector to all the vectors of x, but since the dimensions are respectively (4,) and (100, 4), the operation cannot be done."
      ],
      "metadata": {
        "id": "44cM72XALcar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To allow it, the “broadcasting” mechanism creates `[implicitely]` a matrix of size (100, 4) by replicating the row 100 times."
      ],
      "metadata": {
        "id": "o7_ZlzrdLkHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisely, broadcasting proceeds as follows:\n",
        "\n",
        "1.   If one of the tensors has fewer dimensions than the other, it is reshaped by adding as many dimensions of size 1 as necessary in the front; then\n",
        "\n",
        "2.  for every dimension mismatch, if one of the two tensors is of size one, it is expanded along this axis by replicating coefficients.\n",
        "\n",
        "If there is a tensor size mismatch for one of the dimension and neither of them is one, the operation fails"
      ],
      "metadata": {
        "id": "eP3Dcv80Ln92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting example\n",
        "\n",
        "A = torch.tensor([\n",
        "                  [1.],\n",
        "                  [2.],\n",
        "                  [3.],\n",
        "                  [4.]\n",
        "])\n",
        "\n",
        "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
        "\n",
        "print(A.shape), print(B.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYn0muRwLGmI",
        "outputId": "d70e1d68-2d44-4737-87c2-2fdb46aed8cc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1])\n",
            "torch.Size([1, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(A+B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwyQd6vsMTyw",
        "outputId": "484c4370-32c4-4020-e604-1b45600e54c9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6., -4.,  6., -4.,  6.],\n",
            "        [ 7., -3.,  7., -3.,  7.],\n",
            "        [ 8., -2.,  8., -2.,  8.],\n",
            "        [ 9., -1.,  9., -1.,  9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example,\n",
        "\n",
        "- `A` is of size `(4,1)`\n",
        "- `B` is of size `(1,5)`\n",
        "\n",
        "Following the procedure of the previous slide,\n",
        "\n",
        "Both tensors have two dimensions;\n",
        "\n",
        "Then, for each of the two dimensions:\n",
        "\n",
        "1.  On dimension `0`, `A` has `4` rows, while `B` has `1`. Therefore, `B` is expanded along this dimension by replicating its row `4` times. The “new” `B` is of size `(4,5)`.\n",
        "\n",
        "2.  On dimension `1`, `A` has `1` column, while `B` has `5`. Therefore, `A` is expanded along this dimension by replicating its column `5` times. The\n",
        "“new” `A` is of size `(4,5)`.\n",
        "\n",
        "3. The operation can be perform on\n",
        "these two tensors of size `(4,5)`.\n",
        "\n",
        "\n",
        "Note that all this is transparent and that no copy is actually made."
      ],
      "metadata": {
        "id": "gnvOFvs4Mf87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jtcZp_t2Mdjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.6 Tensor Internals"
      ],
      "metadata": {
        "id": "yy1D1FKoRduc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2,3)\n",
        "print(x.storage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE2yy1kRRhCo",
        "outputId": "618c6f9b-1139-411c-feea-cea998674f4e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            "[torch.FloatStorage of size 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = x.storage()\n",
        "q[0] = 1\n",
        "print(q), print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpHSvGH_RlEk",
        "outputId": "fdf3ca95-a6cb-4075-8873-a67613445f3c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1.0\n",
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            " 0.0\n",
            "[torch.FloatStorage of size 6]\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.arange(0.0,20.0).storage()\n",
        "x = torch.empty(0).set_(q, storage_offset=6,size = (3,2),stride=(4,1))"
      ],
      "metadata": {
        "id": "a64_bUmrRtqh"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkIenseGSfGN",
        "outputId": "54e21a51-548f-495e-ad21-4d3dc090560b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  7.],\n",
              "        [10., 11.],\n",
              "        [14., 15.]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The offset is the location of the first coefficient of the tensor in the storage\n",
        "- The stride is the number of memory elements that should be skipped to go one element the following one in that dimension.\n",
        "\n",
        "- On the illustration, tensor x starts at element 5 of the storage.\n",
        "\n",
        "- We move along dimension 0 by jumping of 4 elements in memory:"
      ],
      "metadata": {
        "id": "kNOq9derSpFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We can explicitly create different “views” of the same storage"
      ],
      "metadata": {
        "id": "0eju42nES33n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = torch.linspace(1, 4, 4)\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ayTShjzSlhB",
        "outputId": "42a0ea44-5b4f-445a-f662-f3abe6cad0e4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(0.).set_(n.storage(), 1, (3, 3), (0, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wAJCqxVS6uZ",
        "outputId": "78c013d3-fcae-4506-959d-49752a6f0c4a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3., 4.],\n",
              "        [2., 3., 4.],\n",
              "        [2., 3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(0.).set_(n.storage(), 1, (2, 4), (1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjSH5chSTACz",
        "outputId": "15131348-c59a-49af-b9dd-1c4d32d61e0d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is in particular how transpositions and broadcasting are implemented."
      ],
      "metadata": {
        "id": "cPh2pUhPTD_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(100, 100)\n",
        "x.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g83P-go5TB5l",
        "outputId": "3b8d5454-8c01-4ab9-bbed-bf1c654c522d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.t()\n",
        "y.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMa0NyhTTHqY",
        "outputId": "4d6d293f-38a2-4d9f-84ce-405a48c72f46"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main idea of functions like `view`, `narrow`, `transpose`, etc. and of operations involving broadcasting is to never replicate data in memory, but to “play” with the offsets and strides of the underlying storage."
      ],
      "metadata": {
        "id": "-ataCiBJTPRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This organization explains the following (maybe surprising) error"
      ],
      "metadata": {
        "id": "o92vhewKTU5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(100, 100)\n",
        "x.t().view(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "imqaV-fWTK45",
        "outputId": "2ff2937b-c5de-406e-c5c5-9be83f9b0adf"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-c6fa27a09931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x.t()` shares `x’s` storage and cannot be “flattened” to 1d."
      ],
      "metadata": {
        "id": "cWRMzfI9TfhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be fixed with `contiguous()`, which returns a contiguous version of the tensor,\n",
        "making a copy if needed.\n",
        "The function `reshape()` combines `view()`and `contiguous()`.\n"
      ],
      "metadata": {
        "id": "aV_2oVnETkQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L72W_cnZTY1_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}